_target_: mbrlax.models.model.build_Model_from_Posterior
posterior:
  _target_: mbrlax.models.laplace.initialise
  network: ${network}
  likelihood: ${likelihood}
  subset_of_weights: "last_layer"
train_fn:
  _target_: mbrlax.models.training.build_train_from_posterior
  posterior: ${model.posterior}
  num_iterations: 80000
  batch_size: 64
  optimizer:
    _target_: optax.adam
    learning_rate: 1e-4
  key:
    _target_: jax.random.PRNGKey
    seed: ${experiment.random_seed}
  early_stop:
    _target_: flax.training.early_stopping.EarlyStopping
    min_delta: 0
    patience: 500
#
#
# _target_: mbrlax.models.laplace.lllaplace.build_model
# network: ${network}
# num_epochs: 80000
# batch_size: 64
# optimizer:
#   _target_: optax.adam
#   learning_rate: 1e-4
# key:
#   _target_: jax.random.PRNGKey
#   seed: ${experiment.random_seed}
# early_stop:
#   _target_: flax.training.early_stopping.EarlyStopping
#   min_delta: 0
#   patience: 500

#   _target_: mbrlax.models.lllaplace.LLLaplace
#   network: ${nwork}
#   input_dim: ${input_dim}
# training:
#   loss:
#     _target_: mbrlax.models.mlp.loss
#     _partial_: true
#   # min_delta: 1e-3
#   min_delta: 0
#   # patience: 5
#   patience: 500
#   # patience: 500
#   num_epochs: 80000
#   # num_epochs: 8
#   batch_size: 64
#   # num_epochs: 80
#   # logging_epoch_freq: 1000 # monitoring config
#   save: True
# model:
#   _target_: examples.train.BayesianLastLayerMLP
#   # features: [2, 3, 4, 5, 6]
#   features: [10, 10, 10, 10, 6]
# training:
#   optimizer:
#     _target_: optax.adam
#     learning_rate: 1e-4
#   loss:
#     _target_: mbrlax.models.mlp.loss
#     _partial_: true
#   # min_delta: 1e-3
#   min_delta: 0
#   # patience: 5
#   patience: 500
#   # patience: 500
#   num_epochs: 80000
#   # num_epochs: 8
#   batch_size: 64
#   # num_epochs: 80
#   # logging_epoch_freq: 1000 # monitoring config
#   save: True
